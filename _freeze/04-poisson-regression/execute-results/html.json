{
  "hash": "611ce44a180835b89660f2e9bdd3ab61",
  "result": {
    "engine": "knitr",
    "markdown": "# Poisson Regression\n\nStub for Poisson regression content\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tidyverse\"); theme_set(theme_bw())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4.9000     ✔ readr     2.1.5     \n✔ forcats   1.0.0          ✔ stringr   1.5.1     \n✔ ggplot2   3.5.1          ✔ tibble    3.2.1     \n✔ lubridate 1.9.3          ✔ tidyr     1.3.1     \n✔ purrr     1.0.2          \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(\"ggResidpanel\")\n```\n:::\n\n\n\n\n\n## Model\n\nLet $Y_i\\in\\{0,1,2,\\ldots\\}$ be a count (typically over some amount of time\nor some amount of space) with associated explanatory variables \n$X_{i,1}, \\ldots, X_{i,p}$.\n\nThen a Poisson regression model is \n$$\nY_i \\ind Po(\\lambda_i) \n$$\nand\n$$\n\\log(\\lambda_i) \n= \\beta_0+\\beta_1 X_{i,1} + \\beta_2 X_{i,2} + \\cdots +\\beta_p X_{i,p} \n$$\n\nAs a reminder, $E[Y_i] = Var[Y_i] = \\lambda_i$ and thus the variance of the \nobservations increases as the mean increases. \n\n\n## Interpretation\n\nWhen all explanatory variables are zero, then \n$$ \nE[Y_i|X_{i,1}=0, \\ldots,X_{i,p}=0]  = \\lambda_i  = e^{\\beta_0}\n$$\n\nthus $\\beta_0$ determines the \\alert{expected response when all explanatory\nvariables are zero}.\n\nMore generally, \n$$ \nE[Y_i|X_{i,1}=x_1, \\ldots,X_{i,p}=x_p] \n \n= e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_px_p}.\n$$\n\nIf $X_{i,1}$  increases by one unit, we have \n$$ \nE[Y_i|X_{i,1}=x_1+1, \\ldots,X_{i,p}=x_p] \n \n= e^{\\beta_0+\\beta_1(x_1+1)+\\cdots+\\beta_px_p}\n\n= e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_px_p}e^{\\beta_1}\n$$\n\nThus \n$$\n\\frac{E[Y_i|X_{i,1}=x_1+1, \\ldots,X_{i,p}=x_p]}{E[Y_i|X_{i,1}=x_1\\phantom{+1}, \\ldots,X_{i,p}=x_p]} \n \n= e^{\\beta_1}.\n$$\n\nThus $e^{\\beta_p}$ is the *multiplicative effect* on the mean response for\na one unit increase in the associated explanatory variable when holding all\nother explanatory variables constant.\n\n## Assumptions\n\n- Independent observations\n- Expected response \n\n## Diagnostics\n\n\n\n## Superbowl scores\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From https://www.espn.com/nfl/superbowl/history/winners\nsuperbowl_scores <- read_csv('data/superbowl_scores.csv') |>\n  tidyr::separate(RESULT, \n                  c(\"winning_points\",\n                    \"losing_points\"),\n                  sep = \", \") |>\n  mutate(\n    winning_points = as.numeric(str_extract(winning_points, \"(\\\\d)+\")),\n    losing_points  = as.numeric(str_extract(losing_points,  \"(\\\\d)+\")),\n    \n    DATE = as.Date(DATE, format = \"%b. %d, %Y\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 59 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NO., DATE, SITE, RESULT\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(superbowl_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  NO.   DATE       SITE                          winning_points losing_points\n  <chr> <date>     <chr>                                  <dbl>         <dbl>\n1 I     1967-01-15 Los Angeles Memorial Coliseum             35            10\n2 II    1968-01-14 Orange Bowl (Miami)                       33            14\n3 III   1969-01-12 Orange Bowl (Miami)                       16             7\n4 IV    1970-01-11 Tulane Stadium (New Orleans)              23             7\n5 V     1971-01-17 Orange Bowl (Miami)                       16            13\n6 VI    1972-01-16 Tulane Stadium (New Orleans)              24             3\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(superbowl_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     NO.                 DATE                SITE           winning_points \n Length:59          Min.   :1967-01-15   Length:59          Min.   :13.00  \n Class :character   1st Qu.:1981-07-26   Class :character   1st Qu.:23.50  \n Mode  :character   Median :1996-01-28   Mode  :character   Median :31.00  \n                    Mean   :1996-01-28                      Mean   :30.22  \n                    3rd Qu.:2010-08-08                      3rd Qu.:35.00  \n                    Max.   :2025-02-09                      Max.   :55.00  \n losing_points  \n Min.   : 3.00  \n 1st Qu.:10.00  \n Median :17.00  \n Mean   :16.66  \n 3rd Qu.:21.00  \n Max.   :35.00  \n```\n\n\n:::\n:::\n\n\n\n\n\nHow have the winning points changed over time?\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(superbowl_scores,\n       aes(x = DATE, y = winning_points)) + \n  geom_point() +\n  scale_y_log10() + # Consistent with Poisson regression\n  labs(\n    x = \"Year\",\n    y = 'Points scored by the winning team',\n    title = 'Superbowl'\n  )\n```\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-winning-points-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n\nLet's fit a Poisson regression model using winning points as the response \nvariable and DATE as the explanatory variable. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(winning_points ~ DATE, \n         data = superbowl_scores, \n         family = \"poisson\")      # Poisson regression\n\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = winning_points ~ DATE, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n(Intercept)         DATE  \n  3.351e+00    5.981e-06  \n\nDegrees of Freedom: 58 Total (i.e. Null);  57 Residual\nNull Deviance:\t    174.5 \nResidual Deviance: 172.1 \tAIC: 482.9\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = winning_points ~ DATE, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 3.351e+00  4.402e-02  76.119   <2e-16 ***\nDATE        5.981e-06  3.804e-06   1.572    0.116    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 174.53  on 58  degrees of freedom\nResidual deviance: 172.05  on 57  degrees of freedom\nAIC: 482.94\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n\nWhen using a Date object, R uses the underlying numeric coding.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuperbowl_scores$DATE[[1]]             # date written in ISO 8601\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"1967-01-15\"\n```\n\n\n:::\n\n```{.r .cell-code}\nas.numeric(superbowl_scores$DATE[[1]]) # R's numeric encoding\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1082\n```\n\n\n:::\n\n```{.r .cell-code}\nsuperbowl_scores$DATE[[1]] - as.Date(\"1970-01-01\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of -1082 days\n```\n\n\n:::\n:::\n\n\n\n\n\nThus when interpreting a coefficient when using a Date explanatory variable, \nwe interpret the increase **per day**. \nIn this case, we probably wanted a **per year** interpretation. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuperbowl_scores_with_year <- superbowl_scores |>\n  mutate(\n    year = as.numeric(format(DATE, \"%Y\"))\n  )\n\nhead(superbowl_scores_with_year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  NO.   DATE       SITE                       winning_points losing_points  year\n  <chr> <date>     <chr>                               <dbl>         <dbl> <dbl>\n1 I     1967-01-15 Los Angeles Memorial Coli…             35            10  1967\n2 II    1968-01-14 Orange Bowl (Miami)                    33            14  1968\n3 III   1969-01-12 Orange Bowl (Miami)                    16             7  1969\n4 IV    1970-01-11 Tulane Stadium (New Orlea…             23             7  1970\n5 V     1971-01-17 Orange Bowl (Miami)                    16            13  1971\n6 VI    1972-01-16 Tulane Stadium (New Orlea…             24             3  1972\n```\n\n\n:::\n:::\n\n\n\n\n\n\nRerun the regression\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(winning_points ~ year, \n         data = superbowl_scores_with_year,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = winning_points ~ year, family = \"poisson\", data = superbowl_scores_with_year)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)\n(Intercept) -0.955427   2.777922  -0.344    0.731\nyear         0.002186   0.001391   1.571    0.116\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 174.53  on 58  degrees of freedom\nResidual deviance: 172.06  on 57  degrees of freedom\nAIC: 482.95\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(cbind(coef(m), confint(m)))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %\n(Intercept) 0.3846478 0.001655571 88.839080\nyear        1.0021884 0.999459987  1.004926\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate the percentage increase\nperinc <- 100*(exp(c(coef(m)[2], confint(m)[2,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       year       2.5 %      97.5 % \n 0.21883878 -0.05400132  0.49261348 \n```\n\n\n:::\n:::\n\n\n\n\n\nWe ran a Poisson regression with number of points the winning team scored on\nyear. \nAccording to the model, the expected points in 1970 for the winning team is \n0 with a 95\\% confidence\ninterval of (0, 89).\nThe percentage increase in points by the winning team per year is\n0.2\\% (-0.1\\%, 0.5\\%).\n\n\n\nThe Poisson regression does indicate some *overdispersion*, \ni.e. that the variance is larger than the mean. \nA quick check looks at the residual deviance relative to its degrees of freedom.\nIf there is no overdispersion, then the residual deviance should have a \nchi-squared distribution with the indicated degrees of freedom. \nThus, if the residual deviance is very large compared to its degrees of freedom\nwe likely have overdispersion. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# p-value for an overdispersion test\n1 - pchisq(m$deviance, m$df.residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.763034e-13\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(superbowl_scores_with_year,\n       aes(x = year,\n           y = winning_points)) +\n  geom_point() +\n  scale_y_log10() +\n  geom_line(aes(y = fitted(m)), col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-scores-plot-with-line-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Difference in points\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- superbowl_scores_with_year |>\n  pivot_longer(cols = c(\"winning_points\", \"losing_points\"),\n               names_to = \"team\",\n               values_to = \"points\") |>\n  mutate(\n    team = gsub(\"_points\", \"\", team)\n  )\n```\n:::\n\n\n\n\n\nSimple regression using binary variable \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team, \n         data = d,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team, family = \"poisson\", data = d)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.81307    0.03189   88.20   <2e-16 ***\nteamwinning  0.59544    0.03973   14.99   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 385.82  on 116  degrees of freedom\nAIC: 964.53\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         2.5 %   97.5 %\n(Intercept) 16.661017 15.64106 17.72435\nteamwinning  1.813835  1.67844  1.96130\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(c(coef(m)[2], confint(m)[2,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n:::\n\n\n\n\n\nWe ran a Poisson regression with number of points scored and winning/losing\nteam as the explanatory variable.\nAccording to the model, the expected points for the losing team is \n17 with a 95\\% confidence\ninterval of (16, 18).\nThe percentage increase in points by the winning team compared to the losing \nteam is\n81.4\\% (67.8\\%, 96.1\\%).\n\n\n\n### Points after adjusting for year\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team + year, \n         data = d,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team + year, family = \"poisson\", data = d)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.447123   2.236836  -3.776 0.000159 ***\nteamwinning  0.595443   0.039726  14.989  < 2e-16 ***\nyear         0.005639   0.001120   5.037 4.74e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 360.38  on 115  degrees of freedom\nAIC: 941.09\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                2.5 %     97.5 %\n(Intercept) 0.0002145166 2.664770e-06 0.01713677\nteamwinning 1.8138351983 1.678440e+00 1.96130036\nyear        1.0056550018 1.003452e+00 1.00786601\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(cbind(coef(m)[2:3], confint(m)[2:3,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %     97.5 %\nteamwinning 81.3835198 67.8439973 96.1300364\nyear         0.5655002  0.3451999  0.7866013\n```\n\n\n:::\n:::\n\n\n\n\n\nWe ran a Poisson regression with number of points scored with winning/losing\nteam and year as the explanatory variables.\nAccording to the model, the expected points for the losing team is \n0 with a 95\\% confidence\ninterval of (0, 0).\nThe percentage increase in points by the winning team compared to the losing \nteam is\n81.4\\% (67.8\\%, 96.1\\%).\nThe percentage increase in points by the both teams per year is\n0.6\\% (0.3\\%, 0.8\\%).\n\n\n### Interaction\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team * year, # Note the *\n         data = d,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team * year, family = \"poisson\", data = d)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      -21.105150   3.791641  -5.566 2.60e-08 ***\nteamwinning       20.149723   4.700361   4.287 1.81e-05 ***\nyear               0.011973   0.001896   6.314 2.72e-10 ***\nteamwinning:year  -0.009787   0.002352  -4.161 3.17e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 342.99  on 114  degrees of freedom\nAIC: 925.7\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                     2.5 %       97.5 %\n(Intercept)      6.825740e-10 3.953390e-13 1.130257e-06\nteamwinning      5.635255e+08 5.688603e+04 5.724489e+12\nyear             1.012045e+00 1.008299e+00 1.015823e+00\nteamwinning:year 9.902610e-01 9.857006e-01 9.948310e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(cbind(coef(m)[2:3], confint(m)[2:3,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                2.5 %       97.5 %\nteamwinning 5.635255e+10 5.688503e+06 5.724489e+14\nyear        1.204467e+00 8.299034e-01 1.582346e+00\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d,\n       aes(x = year,\n           y = points,\n           color = team,\n           shape = team)) + \n  geom_point() + \n  scale_y_log10() +\n  geom_smooth(method = \"glm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-interaction-plot-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "04-poisson-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}