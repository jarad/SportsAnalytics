{
  "hash": "8f64eb8f4779f2f41eb51232ab582fa5",
  "result": {
    "engine": "knitr",
    "markdown": "# Poisson Regression\n\nStub for Poisson regression content\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tidyverse\"); theme_set(theme_bw())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'purrr' was built under R version 4.4.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4.9000     ✔ readr     2.1.5     \n✔ forcats   1.0.0          ✔ stringr   1.5.1     \n✔ ggplot2   3.5.1          ✔ tibble    3.2.1     \n✔ lubridate 1.9.3          ✔ tidyr     1.3.1     \n✔ purrr     1.0.4          \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(\"ggResidpanel\")\n```\n:::\n\n\n## Model\n\nLet $Y_i\\in\\{0,1,2,\\ldots\\}$ be a count (typically over some amount of time\nor some amount of space) with associated explanatory variables \n$X_{i,1}, \\ldots, X_{i,p}$.\n\nThen a Poisson regression model is \n$$\nY_i \\stackrel{ind}{\\sim} Po(\\lambda_i) \n$$\nand\n$$\n\\log(\\lambda_i) \n= \\beta_0+\\beta_1 X_{i,1} + \\beta_2 X_{i,2} + \\cdots +\\beta_p X_{i,p} \n$$\n\nAs a reminder, $E[Y_i] = Var[Y_i] = \\lambda_i$ and thus the variance of the \nobservations increases as the mean increases. \n\n\n## Interpretation\n\nWhen all explanatory variables are zero, then \n$$ \nE[Y_i|X_{i,1}=0, \\ldots,X_{i,p}=0]  = \\lambda_i  = e^{\\beta_0}\n$$\n\nthus $\\beta_0$ determines the **expected response when all explanatory variables are zero**.\n\nMore generally, \n$$ \nE[Y_i|X_{i,1}=x_1, \\ldots,X_{i,p}=x_p] \n= e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_px_p}.\n$$\n\nIf $X_{i,1}$  increases by one unit, we have \n$$ \nE[Y_i|X_{i,1}=x_1+1, \\ldots,X_{i,p}=x_p] \n= e^{\\beta_0+\\beta_1(x_1+1)+\\cdots+\\beta_px_p}\n= e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_px_p}e^{\\beta_1}\n$$\n\nThus \n$$\n\\frac{E[Y_i|X_{i,1}=x_1+1, \\ldots,X_{i,p}=x_p]}{E[Y_i|X_{i,1}=x_1\\phantom{+1}\\,, \\ldots,X_{i,p}=x_p]} \n= e^{\\beta_1}.\n$$\n\nThus $e^{\\beta_p}$ is the **multiplicative effect on the mean response for a one unit increase in the associated explanatory variable when holding all other explanatory variables constant**.\n\nRather than reporting the multiplicate effect, \nit is common to report the **percentage increase** (or decrease).\nTo obtain the percentage increase, we calculate\n$$100(e^{\\beta_p} - 1).$$\n\n## Assumptions\n\n- Observations are independent \n- Observations have a Poisson distribution \n  - Count\n  - Variance is equal to the mean\n- Relationship between expected response relationship and the explanatory variables is given by the model\n\n## Diagnostics\n\nDiagnostics in Poisson regression models is much harder because we don't have \nthe same idea of residuals as we had for linear regression models. \nWe can compute some residuals:\n$$\nr_i = Y_i - \\hat{Y}_i = Y_i - \\lambda_i\n$$\nbut these residuals each have a different variance. \nThus, we need to standardize by calculating the *Pearson residual*\n$$\nr_i^P =  \\frac{Y_i - \\lambda_i}{\\sqrt{\\lambda_i}}\n$$\n\n\n## Superbowl scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_points <- function(points_with_text) {\n  as.numeric(str_extract(points_with_text, \"(\\\\d)+\"))\n}\n\n# From https://www.espn.com/nfl/superbowl/history/winners\nsuperbowl_scores <- read_csv('data/superbowl_scores.csv') |>\n  tidyr::separate(RESULT, \n                  c(\"winning_points\",\n                    \"losing_points\"),\n                  sep = \", \") |>\n  \n  # Extract points \n  mutate(\n    winning_points = get_points(winning_points),\n    losing_points  = get_points(losing_points)\n  ) |>\n  \n  # Create single `points` variable\n  pivot_longer(cols = c(\"winning_points\", \"losing_points\"),\n               names_to = \"team\",\n               values_to = \"points\") |>\n  mutate(\n    team = gsub(\"_points\", \"\", team), \n    \n    # Extract year\n    DATE = as.Date(DATE, format = \"%b. %d, %Y\"),\n    year = as.numeric(format(DATE, format = \"%Y\"))\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 59 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NO., DATE, SITE, RESULT\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(superbowl_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  NO.   DATE       SITE                          team    points  year\n  <chr> <date>     <chr>                         <chr>    <dbl> <dbl>\n1 I     1967-01-15 Los Angeles Memorial Coliseum winning     35  1967\n2 I     1967-01-15 Los Angeles Memorial Coliseum losing      10  1967\n3 II    1968-01-14 Orange Bowl (Miami)           winning     33  1968\n4 II    1968-01-14 Orange Bowl (Miami)           losing      14  1968\n5 III   1969-01-12 Orange Bowl (Miami)           winning     16  1969\n6 III   1969-01-12 Orange Bowl (Miami)           losing       7  1969\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(superbowl_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     NO.                 DATE                SITE               team          \n Length:118         Min.   :1967-01-15   Length:118         Length:118        \n Class :character   1st Qu.:1981-04-26   Class :character   Class :character  \n Mode  :character   Median :1996-01-28   Mode  :character   Mode  :character  \n                    Mean   :1996-01-28                                        \n                    3rd Qu.:2010-11-07                                        \n                    Max.   :2025-02-09                                        \n     points           year     \n Min.   : 3.00   Min.   :1967  \n 1st Qu.:16.00   1st Qu.:1981  \n Median :22.50   Median :1996  \n Mean   :23.44   Mean   :1996  \n 3rd Qu.:31.00   3rd Qu.:2011  \n Max.   :55.00   Max.   :2025  \n```\n\n\n:::\n:::\n\n\n### Points over time\n\nScientific question: How has the number of points changed over time?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(superbowl_scores,\n       aes(x = year, y = points)) + \n  geom_point() +\n  scale_y_log10() + # Consistent with Poisson regression\n  labs(\n    x = \"Year\",\n    y = 'Points scored by the winning team',\n    title = 'Superbowl'\n  )\n```\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-winning-points-plot-1.png){width=672}\n:::\n:::\n\n\nLet's fit a Poisson regression model using points as the response \nvariable and year as the explanatory variable. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Poisson regression\nm <- glm(points ~ year,           # use glm()\n         data = superbowl_scores, \n         family = \"poisson\")      # Poisson regression\n\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = points ~ year, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n(Intercept)         year  \n  -8.105722     0.005639  \n\nDegrees of Freedom: 117 Total (i.e. Null);  116 Residual\nNull Deviance:\t    620.5 \nResidual Deviance: 595.1 \tAIC: 1174\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggResidpanel::resid_panel(m,\n                          qqbands = TRUE,\n                          smoother = TRUE,\n                          type = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/diagnostics-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ year, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.105722   2.236668  -3.624  0.00029 ***\nyear         0.005639   0.001120   5.037 4.74e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 595.10  on 116  degrees of freedom\nAIC: 1173.8\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimates and confidence intervals\ncbind(coef(m), confint(m)) |> exp() |> round(3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  2.5 % 97.5 %\n(Intercept) 0.000 0.000  0.024\nyear        1.006 1.003  1.008\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate the percentage increase\nperinc <- 100*(exp(c(coef(m)[2], confint(m)[2,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year  2.5 % 97.5 % \n  0.57   0.35   0.79 \n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\n\n## Interpretation\n\nWe ran a Poisson regression using number of points each team scored as the \nresponse variable and year as the explanatory variable.\nAccording to the model, the expected points in year 0 for the winning team is \n0 with a 95\\% confidence\ninterval of (0, 0).\nThe percentage increase in points by the winning team per year is\n0.57\\% (0.35\\%, 0.79\\%).\n:::\n\n\nThe Poisson regression does indicate some *overdispersion*, \ni.e. that the variance is larger than the mean. \nA quick check looks at the residual deviance relative to its degrees of freedom.\nIf there is no overdispersion, then the residual deviance should have a \nchi-squared distribution with the indicated degrees of freedom. \nThus, if the residual deviance is very large compared to its degrees of freedom\nwe likely have overdispersion. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# p-value for an overdispersion test\n1 - pchisq(m$deviance, m$df.residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(superbowl_scores,\n       aes(x = year,\n           y = points)) +\n  geom_point() +\n  scale_y_log10() +\n  geom_smooth(method = \"glm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-scores-plot-with-line-1.png){width=672}\n:::\n:::\n\n\n### Winning points vs losing points\n\nSimple regression using binary variable \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team, \n         data = superbowl_scores,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.81307    0.03189   88.20   <2e-16 ***\nteamwinning  0.59544    0.03973   14.99   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 385.82  on 116  degrees of freedom\nAIC: 964.53\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp() |> round(3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    2.5 % 97.5 %\n(Intercept) 16.661 15.641 17.724\nteamwinning  1.814  1.678  1.961\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(c(coef(m)[2], confint(m)[2,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nteamwinning       2.5 %      97.5 % \n   81.38352    67.84400    96.13004 \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note}\n\n## Interpretation\n\nWe ran a Poisson regression with number of points scored and winning/losing\nteam as the explanatory variable.\nAccording to the model, the expected points for the losing team is \n17 with a 95\\% confidence\ninterval of (16, 18).\nThe percentage increase in points by the winning team compared to the losing \nteam is\n81\\% (68\\%, 96\\%).\n:::\n\n\n### Points after adjusting for year\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team + year, \n         data = superbowl_scores,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team + year, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.447123   2.236836  -3.776 0.000159 ***\nteamwinning  0.595443   0.039726  14.989  < 2e-16 ***\nyear         0.005639   0.001120   5.037 4.74e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 360.38  on 115  degrees of freedom\nAIC: 941.09\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp() |> round(3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  2.5 % 97.5 %\n(Intercept) 0.000 0.000  0.017\nteamwinning 1.814 1.678  1.961\nyear        1.006 1.003  1.008\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(cbind(coef(m)[2:3], confint(m)[2:3,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %     97.5 %\nteamwinning 81.3835198 67.8439973 96.1300364\nyear         0.5655002  0.3451999  0.7866013\n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\n\n## Interpretation\n\nWe ran a Poisson regression with number of points scored as the response \nvariable and winning/losing team and year as the explanatory variables.\nAccording to the model, the expected points for the losing team in year 0 is \n0 with a 95\\% confidence\ninterval of (0, 0).\nAfter adjusting for year, the percentage increase in expected points by the winning team compared to the losing team is\n81.4\\% (67.8\\%, 96.1\\%).\nAfter adjusting for winning versus losing team, \nthe percentage increase in expected points by the both teams per year is\n0.6\\% (0.3\\%, 0.8\\%).\n:::\n\n### Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- glm(points ~ team * year,     # Note the * rather than +\n         data = superbowl_scores,\n         family = \"poisson\")\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = points ~ team * year, family = \"poisson\", data = superbowl_scores)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      -21.105150   3.791641  -5.566 2.60e-08 ***\nteamwinning       20.149723   4.700361   4.287 1.81e-05 ***\nyear               0.011973   0.001896   6.314 2.72e-10 ***\nteamwinning:year  -0.009787   0.002352  -4.161 3.17e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 620.54  on 117  degrees of freedom\nResidual deviance: 342.99  on 114  degrees of freedom\nAIC: 925.7\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(coef(m), confint(m)) |> exp()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                     2.5 %       97.5 %\n(Intercept)      6.825740e-10 3.953390e-13 1.130257e-06\nteamwinning      5.635255e+08 5.688603e+04 5.724489e+12\nyear             1.012045e+00 1.008299e+00 1.015823e+00\nteamwinning:year 9.902610e-01 9.857006e-01 9.948310e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc <- 100*(exp(cbind(coef(m)[2:3], confint(m)[2:3,])) - 1) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n```{.r .cell-code}\nperinc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                2.5 %       97.5 %\nteamwinning 5.635255e+10 5.688503e+06 5.724489e+14\nyear        1.204467e+00 8.299034e-01 1.582346e+00\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(superbowl_scores,\n       aes(x = year,\n           y = points,\n           color = team,\n           shape = team)) + \n  geom_point() + \n  scale_y_log10() +\n  geom_smooth(method = \"glm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04-poisson-regression_files/figure-html/superbowl-interaction-plot-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "04-poisson-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}